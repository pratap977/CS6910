{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Adam.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5M-kfLtnQHE"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def adam_grad(layers, curLayer, ey, h, b_sz, eta):\n",
        "  final_dA = []\n",
        "  b_arr = get_batch_indices(b_sz)\n",
        "  beta1, beta2, eps, t=0.9, 0.99, 1e-8, 1\n",
        "\n",
        "  for i in range(1, len(b_arr)):\n",
        "    dA = compute_gradient(layers, currLayer, ey, h, i, b_arr)\n",
        "    for arr in dA\n",
        "      final_dA.append(arr)\n",
        "    dA = np.array(dA).T\n",
        "\n",
        "\n",
        "    start= b_arr[i-1]\n",
        "    end = b_arr[i]\n",
        "\n",
        "    layers[currLayer].dw = 1/b_sz * dA.dot(layers[currLayer].h_prev[:, start:end].T)\n",
        "    layers[currLayer].dw = 1/b_sz*np.sum(dA)\n",
        "\n",
        "    m_w = beta1*layers[currLayer].m_w + (1-beta1) * (layers[curLayer].dw)\n",
        "    m_b = beta1*layers[currLayer].m_b + (1-beta1) * (layers[curLayer].db)\n",
        "\n",
        "    v_w = beta2*layers[currLayer].prev_v_w + (1-beta2) * (layers[curLayer].dw**2)\n",
        "    v_b = beta2*layers[currLayer].prev_v_b + (1-beta2) * (layers[curLayer].db**2)\n",
        "\n",
        "    t=t+1\n",
        "    m_w_hat = m_w/(1-np.power(beta1, t))\n",
        "    m_b_hat = m_b/(1-np.power(beta1, t))\n",
        "\n",
        "    v_w_hat = v_w/(1-np.power(beta2, t))\n",
        "    v_b_hat = v_b/(1-np.power(beta2, t)\n",
        "\n",
        "\n",
        "    #updates\n",
        "    layers[currLayer].w = layers[curLayer].w - (eta/(np.sqrt(v_w_hat + eps)))*m_w_hat\n",
        "    layers[currLayer].b = layers[curLayer].b - (eta/(np.sqrt(v_b_hat + eps)))*m_b_hat\n",
        "\n",
        "    layers[curLayer].prev_v_w = v_w\n",
        "    layers[curLayer].prev_v_b = v_b\n",
        "\n",
        "    layers[curLayer].m_w = m_w\n",
        "    layers[curLayer].m_b = m_b\n",
        "\n",
        "    find_dA = np.array(final_dA).T\n",
        "    layers[curLayer].set_dA(final_dA)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pbBndwHinebn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}