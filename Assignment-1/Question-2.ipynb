!pip install wandb
from keras.datasets import fashion_mnist
import numpy as np
from  matplotlib import pyplot as plt
import time
import math
import wandb
wandb.login()

wandb.init(project="assignment1")

#Loading the data from the fashion_mnist dataset.
((xtrain, ytrain), (xtest, ytest)) = fashion_mnist.load_data()
items=["T-shirt/top", "Trouser","Pullover", "Dress", "Coat", "Sandal", "Shirt", "Sneaker", "Bag","Ankle boot"]

#Creating an array of images from the xtrain array where 1 image for each array is appended.
ig=[]
for i in range(10):
  for j in range(len(ytrain)):
    if ytrain[j]==i:
      ig.append(xtrain[j])
      break;


#printing the probability over the 10 classes.
for i in range(len(ig)):
  plt.subplot(2,5,i+1)
  plt.imshow(ig[i])
  plt.title(items[i])
wandb.log({"imagess":[wandb.Image(img,caption=item) for img,item in zip(ig,items)]})
print(items[i])
plt.show()
wandb.finish()


def sigmoid(x):
  return np.where(x>=0, 1/(1+np.exp(-x)), np.exp(x)/(1+np.exp(x)))

def grad_sigmoid(z):
  d=sigmoid(z)
  return d*(1-d)

def softmax(z):
  mx=np.max(z)
  z=z-mx
  out=np.exp(z)/np.sum(np.exp(z)+1e-9)
  return out

def grad_softmax(yh,ty):
  return yh-ty

def Relu(x):
    return np.maximum(0, x)

def grad_Relu(x):
    return [1 if xi>0 else 0 for xi in x]

def Tanh(Z):
    mx=np.max(Z)
    #numr = np.exp(x-mx) - np.exp(-x-mx)
    #denom=np.exp(x-mx) + np.exp(-x-mx)
    #mn=np.min(Z)
     #if mn<0:
      # a=np.exp(Z-mx+mn)
       #b=np.exp(-Z-mx+mn)
      
       #return (a-b+1e-9)/(a+b+1e-8)
    return np.array([((np.exp(x-mx) - np.exp(-x-mx))/((np.exp(x-mx) + np.exp(-x-mx)))) for x in Z])

def grad_Tanh(x):
    return 1-Tanh(x)**2

def InitParams(x,init):
    weights=[]
    baises=[]
    if(init=='random'):
      weights.append((np.random.randn(x[0],784)))
      baises.append((np.random.randn(x[0])))
      l=len(x)-1
      for i in range(l):
          weights.append(0.1*(np.random.randn(x[i+1],x[i])))
          baises.append(0.1*(np.random.randn(x[i+1])))
      weights.append(0.1*(np.random.randn(10,x[-1])))
      baises.append(0.1*(np.random.randn(10)))
    else:
      weights.append(np.random.randn(x[0], 784)*np.sqrt(2./(x[0] + 784)))
      baises.append(np.zeros(x[0]))
      l=len(x)-1
      for i in range(l):
          weights.append(np.random.randn(x[i], x[i-1])*np.sqrt(2./(x[i] + x[i-1])))
          baises.append(np.zeros(x[i+1]))
      weights.append(np.sqrt(2./(10 + x[-1]))*(np.random.randn(10,x[-1])))
      baises.append((np.zeros(10)))


    return weights,baises

def Feed_Frwd_Nw1(xTr,Weighs,Bais,activation,loss):
  a_i=[]
  h_i=[]
  output=np.arange(10,dtype='float64')
  a_i.append(np.dot(Weighs[0],xTr)+Bais[0])       
  if (activation=='sig'):
    h_i.append(sigmoid(a_i[0]))
  elif (activation=='tanh'):
    h_i.append(Tanh(a_i[0]))
  elif (activation=='relu'):
    h_i.append(Relu(a_i[0]))
  for i in range(1,len(Weighs)-1):
    a_i.append((np.dot(Weighs[i],h_i[i-1])+Bais[i]))
    if (activation=='sig'):
      h_i.append(sigmoid(a_i[i]))
    elif (activation=='tanh'):
      h_i.append(Tanh(a_i[i]))
    elif (activation=='relu'):
      h_i.append(Relu(a_i[i]))
  a_i.append(np.dot(Weighs[-1],h_i[-1])+Bais[-1])
  if (loss=='ce'):
    h_i.append(softmax(a_i[-1]))
  elif (loss=='mse'):
    h_i.append(sigmoid(a_i[-1]))
  yp=h_i[-1]
  return yp,a_i,h_i

def initgrads(N,Nunits):
  dh,da,dw,db=[],[],[],[]
  dw.append(np.zeros((Nunits[0],784)))
  db.append(np.zeros(Nunits[0]))
  da.append(np.zeros(Nunits[0]))
  dh.append(np.zeros(Nunits[0]))
  for i in range(1,N):
    dw.append(np.zeros((Nunits[i],Nunits[i-1])))
    db.append(np.zeros(Nunits[i]))
    da.append(np.zeros(Nunits[i]))
    dh.append(np.zeros(Nunits[i]))
  dw.append(np.zeros((10,Nunits[-1])))
  db.append(np.zeros(10))
  da.append(np.zeros(10))
  dh.append(np.zeros(10))
  return dw,db,da,dh
