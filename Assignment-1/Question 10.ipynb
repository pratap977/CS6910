{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pratap977/CS6910/blob/main/Assignment-1/Question%2010.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KuES9pCbK792"
      },
      "outputs": [],
      "source": [
        "!pip install wandb\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "from  matplotlib import pyplot as plt\n",
        "import time\n",
        "import math\n",
        "import wandb\n",
        "wandb.login()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuWGtSDfLEM5"
      },
      "outputs": [],
      "source": [
        "((xtrain, ytrain), (xtest, ytest)) = mnist.load_data()\n",
        "\n",
        "items=[\"0\", \"1\",\"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\",\"9\"]\n",
        "ftrx=np.zeros((60000,784))\n",
        "ftry=np.zeros((60000,10))\n",
        "ftex=np.zeros((10000,784))\n",
        "ftey=np.zeros((10000,10))\n",
        "for i in range(len(xtrain)):\n",
        "  ftrx[i]=xtrain[i].flatten();\n",
        "  ftrx[i]=ftrx[i]/256\n",
        "  ftry[i][ytrain[i]]=1\n",
        "for i in range(len(xtest)):\n",
        "  ftex[i]=xtest[i].flatten();\n",
        "  ftex[i]=ftex[i]/256\n",
        "  ftey[i][ytest[i]]=1\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0HDXVOAfLR5C"
      },
      "outputs": [],
      "source": [
        "\n",
        "     # activation functions and gradients\n",
        "\n",
        "def sigmoid(x):\n",
        "  return np.where(x>=0, 1/(1+np.exp(-x)), np.exp(x)/(1+np.exp(x)))\n",
        "\n",
        "def grad_sigmoid(z):\n",
        "  return z*(1-z)\n",
        "\n",
        "def softmax(z):\n",
        "  mx=np.max(z)\n",
        "  z=z-mx\n",
        "  out=(np.exp(z)+1e-9)/np.sum(np.exp(z)+1e-9)\n",
        "  return out\n",
        "\n",
        "def grad_softmax(yh,ty):\n",
        "  return yh-ty\n",
        "\n",
        "def Relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def grad_Relu(x):\n",
        "    return [1 if xi>0 else 0 for xi in x]\n",
        "\n",
        "def Tanh(x):\n",
        "  a= 2*np.where(x>=0, 1/(1+np.exp(-2*x)), np.exp(2*x)/(1+np.exp(2*x)))\n",
        "  return a-1\n",
        "\n",
        "\n",
        "def grad_Tanh(x):\n",
        "    return 1-Tanh(x)**2\n",
        "\n",
        "def InitParams(x,init):\n",
        "    weights=[]\n",
        "    baises=[]\n",
        "    if(init=='random'):\n",
        "      weights.append((np.random.randn(x[0],784)))\n",
        "      baises.append((np.random.randn(x[0])))\n",
        "      l=len(x)-1\n",
        "      for i in range(l):\n",
        "          weights.append(0.1*(np.random.randn(x[i+1],x[i])))\n",
        "          baises.append(0.1*(np.random.randn(x[i+1])))\n",
        "      weights.append(0.1*(np.random.randn(10,x[-1])))\n",
        "      baises.append(0.1*(np.random.randn(10)))\n",
        "    else:\n",
        "      weights.append(np.random.randn(x[0], 784)*np.sqrt(2./(784)))\n",
        "      baises.append(np.zeros(x[0]))\n",
        "      l=len(x)-1\n",
        "      for i in range(l):\n",
        "          weights.append(np.random.randn(x[i+1], x[i])*np.sqrt(2./(x[i])))\n",
        "          baises.append(np.zeros(x[i+1]))\n",
        "      weights.append(np.sqrt(2./(x[-1]))*(np.random.randn(10,x[-1])))\n",
        "      baises.append((np.zeros(10)))\n",
        "\n",
        "\n",
        "    return weights,baises\n",
        "\n",
        "\n",
        "\n",
        "def initgrads(N,Nunits):\n",
        "  dh,da,dw,db=[],[],[],[]\n",
        "  dw.append(np.zeros((Nunits[0],784)))\n",
        "  db.append(np.zeros(Nunits[0]))\n",
        "  da.append(np.zeros(Nunits[0]))\n",
        "  dh.append(np.zeros(Nunits[0]))\n",
        "  for i in range(1,N):\n",
        "    dw.append(np.zeros((Nunits[i],Nunits[i-1])))\n",
        "    db.append(np.zeros(Nunits[i]))\n",
        "    da.append(np.zeros(Nunits[i]))\n",
        "    dh.append(np.zeros(Nunits[i]))\n",
        "  dw.append(np.zeros((10,Nunits[-1])))\n",
        "  db.append(np.zeros(10))\n",
        "  da.append(np.zeros(10))\n",
        "  dh.append(np.zeros(10))\n",
        "  return dw,db,da,dh\n",
        "\n",
        "  \n",
        "def Feed_Frwd_Nw1(xTr,Weighs,Bais,activation,loss):\n",
        "  a_i=[]\n",
        "  h_i=[]\n",
        "  a_i.append(np.dot(Weighs[0],xTr)+Bais[0])       \n",
        "  if (activation=='sig'):\n",
        "    h_i.append(sigmoid(a_i[0]))\n",
        "  elif (activation=='tanh'):\n",
        "    h_i.append(Tanh(a_i[0]))\n",
        "  elif (activation=='relu'):\n",
        "    h_i.append(Relu(a_i[0]))\n",
        "  for i in range(1,len(Weighs)-1):\n",
        "    a_i.append((np.dot(Weighs[i],h_i[i-1])+Bais[i]))\n",
        "    if (activation=='sig'):\n",
        "      h_i.append(sigmoid(a_i[i]))\n",
        "    elif (activation=='tanh'):\n",
        "      h_i.append(Tanh(a_i[i]))\n",
        "    elif (activation=='relu'):\n",
        "      h_i.append(Relu(a_i[i]))\n",
        "  a_i.append(np.dot(Weighs[-1],h_i[-1])+Bais[-1])\n",
        "  h_i.append(softmax(a_i[-1])) \n",
        "  yp=h_i[-1]\n",
        "  return yp,a_i,h_i\n",
        "\n",
        "\n",
        "def Back_Prop(ip,ypr,ty,a_i,h_i,W,B,N,nrl,activation,Loss):\n",
        "  k=len(ypr)\n",
        "  dw,db,da,dh=initgrads(N,nrl)\n",
        "  if (Loss==\"ce\"):\n",
        "    dh[-1]=[-(t/ypr) if t==1 else 0 for t in ty ]\n",
        "    da[-1]=ypr-ty\n",
        "  elif (Loss==\"mse\"):\n",
        "    dh[-1]=(ypr-ty)\n",
        "    da[-1]=dh[-1]*(ypr-ypr**2)\n",
        "\n",
        "  db[-1]=da[-1] \n",
        "  dw[-1]=np.dot((da[-1][:,np.newaxis]),(h_i[-2][:,np.newaxis]).T)\n",
        " \n",
        "  for i in range(N-1,-1,-1):\n",
        "    dh[i]=np.squeeze(np.dot(W[i+1].T,da[i+1]))\n",
        "\n",
        "    if (activation=='sig'):\n",
        "      da[i]=dh[i]*grad_sigmoid(h_i[i])\n",
        "    elif (activation=='tanh'):\n",
        "      da[i]=dh[i]*grad_Tanh(a_i[i])\n",
        "    elif (activation=='relu'):\n",
        "      da[i]=dh[i]*grad_Relu(a_i[i])\n",
        "    db[i]=np.copy(da[i])\n",
        "    if (i==0):\n",
        "      dw[i]=np.dot(da[i][:,np.newaxis],ip[:,np.newaxis].T)\n",
        "    else:\n",
        "      dw[i]=np.dot(da[i][:,np.newaxis],h_i[i-1][:,np.newaxis].T)\n",
        "  return dw,db\n",
        "\n",
        "\n",
        "def sum_weights(W):\n",
        "  sum=0\n",
        "  for i in range(len(W)):\n",
        "    sum+=np.sum(W[i])\n",
        "  return sum\n",
        "\n",
        "\n",
        "\n",
        "           # Losses and accuracies\n",
        "def val_acc_loss(W,B,activation,ls_fun,wd):\n",
        "  cost=0\n",
        "  count=0\n",
        "  if (ls_fun=='ce'):\n",
        "    for i in range(len(ftrx[54000:])):\n",
        "      ypr,_,_=Feed_Frwd_Nw1(ftrx[i],W,B,activation,ls_fun)\n",
        "      cost += (np.sum(np.multiply(ftry[i],np.log(ypr))) + wd/2*sum_weights(W) )\n",
        "      if (np.argmax(ypr) ==np.argmax(ftry[i])):\n",
        "        count+=1\n",
        "    return -cost/6000, count/6000\n",
        "    #return np.sum(ay.multiply(np.log(yh)))\n",
        "  elif (ls_fun=='mse'):\n",
        "    for i in range(len(ftrx[54000:])):\n",
        "      ypr,_,_=Feed_Frwd_Nw1(ftrx[i],W,B,activation,ls_fun)\n",
        "      cost+=(0.5*np.sum((ftry[i]- ypr)**2) + wd/2*sum_weights(W) )\n",
        "      if (np.argmax(ypr) ==np.argmax(ftry[i])):\n",
        "        count+=1\n",
        "    return cost/6000, count/6000\n",
        "\n",
        "def train_acc_loss(W,B,activation,ls_fun,wd):\n",
        "  cost=0\n",
        "  count=0\n",
        "  if (ls_fun=='ce'):\n",
        "    for i in range(len(ftrx[:54000])):\n",
        "      ypr,_,_=Feed_Frwd_Nw1(ftrx[i],W,B,activation,ls_fun)\n",
        "      cost += (np.sum(np.multiply(ftry[i],np.log(ypr))) + wd/2*sum_weights(W) )\n",
        "      if (np.argmax(ypr) ==np.argmax(ftry[i])):\n",
        "        count+=1\n",
        "    return -cost/54000, count/54000\n",
        "    #return np.sum(ay.multiply(np.log(yh)))\n",
        "  elif (ls_fun=='mse'):\n",
        "    for i in range(len(ftrx[:54000])):\n",
        "      ypr,_,_=Feed_Frwd_Nw1(ftrx[i],W,B,activation,ls_fun)\n",
        "      cost+=(0.5*np.sum((ftry[i]- ypr)**2) + wd/2*sum_weights(W) )\n",
        "      if (np.argmax(ypr) ==np.argmax(ftry[i])):\n",
        "        count+=1\n",
        "    return cost/54000, count/54000\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def test_acc(W,B,activation,ls_fun):\n",
        "  count=0\n",
        "  predictions=[]\n",
        "  matrix=np.zeros((10,10))\n",
        "  for i in range(len(ftex)):\n",
        "    ypr,_,_=Feed_Frwd_Nw1(ftex[i],W,B,activation,ls_fun)\n",
        "    if (np.argmax(ypr) == ytest[i]):\n",
        "      count+=1\n",
        "    predictions.append(np.argmax(ypr))\n",
        "    matrix[ytest[i]][np.argmax(ypr)]+=1\n",
        "    \n",
        "  lables={}\n",
        "  for i in range(len(items)):\n",
        "    lables[i]=items[i]\n",
        "  wandb.log({\"confusion matrix\": wandb.plot.confusion_matrix(probs=None,\n",
        "                                                              y_true=ytest,\n",
        "                                                              preds=predictions,\n",
        "                                                              class_names=items)})\n",
        "  wandb.log({\"confusion matrix v2.0\": wandb.plots.HeatMap(items, items, matrix, show_text=True),\"Accuracy\":count/len(ytest)})\n",
        "  return count/len(ytest)\n",
        "\n",
        "\n",
        "\n",
        "def gradDecent(ftrx,ftry,init,wd,eta,N,nrl,activation,Ls_fun,epochs,batchsize):\n",
        "  W,B=InitParams(nrl,init)\n",
        "  e=0\n",
        "  while(epochs>0):\n",
        "    e+=1\n",
        "    start = time.time()\n",
        "    epochs-=1\n",
        "    uw,ub,_,_=initgrads(N,nrl)\n",
        "    for i in range(len(ftrx[:54000])):\n",
        "      pred_y,ai,hi=Feed_Frwd_Nw1(ftrx[i],W,B,activation,Ls_fun)\n",
        "      gw,gb=Back_Prop(ftrx[i],pred_y,ftry[i],ai,hi,W,B,N,nrl,activation,Ls_fun)\n",
        "      for j in range(len(gw)):\n",
        "        uw[j]=np.add(uw[j],gw[j]+wd*W[j])\n",
        "        ub[j]=np.add(ub[j],gb[j]+wd*B[j])\n",
        "      if((i+1)%batchsize==0 or i==53999):\n",
        "        for k in range(len(gw)):\n",
        "          W[k]=np.subtract(W[k],eta*uw[k]/batchsize)\n",
        "          B[k]=np.subtract(B[k],eta*ub[k]/batchsize)\n",
        "          uw[k]=np.subtract(uw[k],uw[k])\n",
        "          ub[k]=np.subtract(ub[k],ub[k]) \n",
        "            \n",
        "    end = time.time() \n",
        "    tloss,tacc=train_acc_loss(W,B,activation,Ls_fun,wd)\n",
        "    vloss,vacc=val_acc_loss(W,B,activation,Ls_fun,wd)\n",
        "    wandb.log({\"epoch\":e,\"Train_loss\":tloss,\"Train_acc\":tacc,\"val_loss\":vloss,\"val_Accuracy\":vacc})\n",
        "    #print(\"epochs :\",e,\"train_loss :\",tloss,\"  Train_acc:\",tacc,\"val_loss:\",vloss,\"val_Accuracy:\",vacc,\"    time:\",math.ceil(end-start))\n",
        "  test_acc(W,B,activation,Ls_fun)  \n",
        "  return hi,W,B\n",
        "\n",
        "\n",
        "import copy \n",
        "def Momentum(ftrx,ftry,init,batchsize,gamma,wd,eta,N,nrl,activation,Ls_fun,epochs=1):\n",
        "  W,B=InitParams(nrl,init)\n",
        "  vw,vb,_,_=initgrads(N,nrl)\n",
        "  pw,pb,_,_=initgrads(N,nrl)\n",
        "  e=0\n",
        "  while(epochs>0):\n",
        "    e+=1\n",
        "    start = time.time()\n",
        "    epochs-=1\n",
        "    uw,ub,_,_=initgrads(N,nrl)\n",
        "    for i in range(len(ftrx[:54000])):\n",
        "      pred_y,ai,hi=Feed_Frwd_Nw1(ftrx[i],W,B,activation,Ls_fun)\n",
        "      gw,gb=Back_Prop(ftrx[i],pred_y,ftry[i],ai,hi,W,B,N,nrl,activation,Ls_fun)\n",
        "      for j in range(len(gw)):\n",
        "        uw[j]=np.add(uw[j],gw[j]+wd*W[j])\n",
        "        ub[j]=np.add(ub[j],gb[j]+wd*B[j])\n",
        "      if((i+1)%batchsize==0 or i==53999):\n",
        "        for k in range(len(gw)):\n",
        "          # z1,z2=W[k],B[k]\n",
        "          vw[k]=np.add(gamma*pw[k],eta*uw[k]/batchsize)\n",
        "          vb[k]=np.add(gamma*pb[k],eta*ub[k]/batchsize)\n",
        "          W[k]=np.subtract(W[k],vw[k])\n",
        "          B[k]=np.subtract(B[k],vb[k])\n",
        "          pw[k]=copy.deepcopy(vw[k])\n",
        "          pb[k]=copy.deepcopy(vb[k])\n",
        "          uw[k]=np.subtract(uw[k],uw[k])\n",
        "          ub[k]=np.subtract(ub[k],ub[k]) \n",
        "            \n",
        "    end = time.time() \n",
        "    tloss,tacc=train_acc_loss(W,B,activation,Ls_fun,wd)\n",
        "    vloss,vacc=val_acc_loss(W,B,activation,Ls_fun,wd)\n",
        "    wandb.log({\"epoch\":e,\"Train_loss\":tloss,\"Train_acc\":tacc,\"val_loss\":vloss,\"val_Accuracy\":vacc})\n",
        "    #print(\"epochs :\",e,\"train_loss :\",tloss,\"  Train_acc:\",tacc,\"val_loss:\",vloss,\"val_Accuracy:\",vacc,\"    time:\",math.ceil(end-start))\n",
        "  test_acc(W,B,activation,Ls_fun)  \n",
        "  return hi,W,B\n",
        "\n",
        "import copy \n",
        "def Nesterov(ftrx,ftry,init,batchsize,gamma,wd,eta,N,nrl,activation,Ls_fun,epochs=1):\n",
        "  W,B=InitParams(nrl,init)\n",
        "  vw,vb,_,_=initgrads(N,nrl)\n",
        "  pw,pb,_,_=initgrads(N,nrl)\n",
        "  w,b=copy.deepcopy(W),copy.deepcopy(B)\n",
        "  e=0\n",
        "  while(epochs>0):\n",
        "    start = time.time()\n",
        "    e+=1\n",
        "    start = time.time()\n",
        "    epochs-=1 \n",
        "    uw,ub,_,_=initgrads(N,nrl)\n",
        "    for i in range(len(ftrx)):\n",
        "      pred_y,ai,hi=Feed_Frwd_Nw1(ftrx[i],W,B,activation,Ls_fun) \n",
        "      gw,gb=Back_Prop(ftrx[i],pred_y,ftry[i],ai,hi,w,b,N,nrl,activation,Ls_fun)\n",
        "      for j in range(len(gw)):\n",
        "        uw[j]=np.add(uw[j],gw[j]+wd*W[j])\n",
        "        ub[j]=np.add(ub[j],gb[j]+wd*B[j])\n",
        "      if((i+1)%batchsize==0 or i==53999):\n",
        "        for k in range(len(gw)):\n",
        "          # z1,z2=W[k],B[k]\n",
        "          vw[k]=np.add(gamma*pw[k],eta*uw[k]/batchsize)\n",
        "          vb[k]=np.add(gamma*pb[k],eta*ub[k]/batchsize)\n",
        "          W[k]=np.subtract(W[k],vw[k])\n",
        "          B[k]=np.subtract(B[k],vb[k])\n",
        "          pw[k]=copy.deepcopy(vw[k])\n",
        "          pb[k]=copy.deepcopy(vb[k])\n",
        "          uw[k]=np.subtract(uw[k],uw[k])\n",
        "          ub[k]=np.subtract(ub[k],ub[k])\n",
        "          for k in range(len(dw)):\n",
        "            w[k]=np.subtract(W[k],gamma*pw[k])\n",
        "            b[k]=np.subtract(B[k],gamma*pb[k])    \n",
        "    end = time.time() \n",
        "    tloss,tacc=train_acc_loss(W,B,activation,Ls_fun,wd)\n",
        "    vloss,vacc=val_acc_loss(W,B,activation,Ls_fun,wd)\n",
        "    wandb.log({\"epoch\":e,\"Train_loss\":tloss,\"Train_acc\":tacc,\"val_loss\":vloss,\"val_Accuracy\":vacc})\n",
        "    #print(\"epochs :\",e,\"train_loss :\",tloss,\"  Train_acc:\",tacc,\"val_loss:\",vloss,\"val_Accuracy:\",vacc,\"    time:\",math.ceil(end-start))\n",
        "  test_acc(W,B,activation,Ls_fun)  \n",
        "  return hi,W,B\n",
        "\n",
        "def rmsprop(ftrx,ftry,init,batchsize,eps,beta,wd,eta,N,nrl,activation,Ls_fun,epochs=1):\n",
        "  W,B=InitParams(nrl,init)\n",
        "  vw,vb,_,_=initgrads(N,nrl)\n",
        "  e=0\n",
        "  while(epochs>0):\n",
        "    e+=1\n",
        "    start = time.time()\n",
        "    epochs-=1\n",
        "    uw,ub,_,_=initgrads(N,nrl)\n",
        "    for i in range(len(ftrx[:54000])):\n",
        "      pred_y,ai,hi=Feed_Frwd_Nw1(ftrx[i],W,B,activation,Ls_fun)\n",
        "      gw,gb=Back_Prop(ftrx[i],pred_y,ftry[i],ai,hi,W,B,N,nrl,activation,Ls_fun)\n",
        "      for j in range(len(gw)):\n",
        "        uw[j]=np.add(uw[j],gw[j]+wd*W[j])\n",
        "        ub[j]=np.add(ub[j],gb[j]+wd*B[j])\n",
        "      if((i+1)%batchsize==0 or i==53999):\n",
        "        for k in range(len(gw)):\n",
        "          vw[k]=np.add(beta*vw[k],(1-beta)*uw[k]**2)\n",
        "          vb[k]=np.add(beta*vb[k],(1-beta)*ub[k]**2)\n",
        "          W[k]=np.subtract(W[k],((eta/batchsize)/np.sqrt(vw[k]+eps))*uw[k])\n",
        "          B[k]=np.subtract(B[k],((eta/batchsize)/np.sqrt(vb[k]+eps))*ub[k])\n",
        "          uw[k]=np.subtract(uw[k],uw[k])\n",
        "          ub[k]=np.subtract(ub[k],ub[k]) \n",
        "            \n",
        "    end = time.time() \n",
        "    tloss,tacc=train_acc_loss(W,B,activation,Ls_fun,wd)\n",
        "    vloss,vacc=val_acc_loss(W,B,activation,Ls_fun,wd)\n",
        "    wandb.log({\"epoch\":e,\"Train_loss\":tloss,\"Train_acc\":tacc,\"val_loss\":vloss,\"val_Accuracy\":vacc})\n",
        "    #print(\"epochs :\",e,\"train_loss :\",tloss,\"  Train_acc:\",tacc,\"val_loss:\",vloss,\"val_Accuracy:\",vacc,\"    time:\",math.ceil(end-start))\n",
        "  test_acc(W,B,activation,Ls_fun)  \n",
        "  return hi,W,B\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def Adam(ftrx,ftry,init,batchsize,eps,beta1,beta2,wd,eta,N,nrl,activation,Ls_fun,epochs=1):\n",
        "  W,B=InitParams(nrl,init)\n",
        "  vw,vb,_,_=initgrads(N,nrl)\n",
        "  mw,mb,_,_=initgrads(N,nrl)\n",
        "  beta1=0.9\n",
        "  e=0\n",
        "  t=1\n",
        "  while(epochs>0):\n",
        "    e+=1\n",
        "    start = time.time()\n",
        "    epochs-=1\n",
        "    uw,ub,_,_=initgrads(N,nrl)\n",
        "    for i in range(len(ftrx[:54000])):\n",
        "      pred_y,ai,hi=Feed_Frwd_Nw1(ftrx[i],W,B,activation,Ls_fun)\n",
        "      gw,gb=Back_Prop(ftrx[i],pred_y,ftry[i],ai,hi,W,B,N,nrl,activation,Ls_fun)\n",
        "      for j in range(len(gw)):\n",
        "        uw[j]=np.add(uw[j],gw[j]+wd*W[j])\n",
        "        ub[j]=np.add(ub[j],gb[j]+wd*B[j])\n",
        "      if((i+1)%batchsize==0 or i==53999):\n",
        "        t+=1\n",
        "        for k in range(len(gw)):\n",
        "          vw[k]=np.add(beta2*vw[k],(1-beta2)*uw[k]**2)\n",
        "          vb[k]=np.add(beta2*vb[k],(1-beta2)*ub[k]**2)\n",
        "\n",
        "          mw[k]=np.add(beta1*mw[k],(1-beta1)*uw[k])\n",
        "          mb[k]=np.add(beta1*mb[k],(1-beta1)*ub[k])\n",
        "          mw[k]/=(1-np.power(beta1,t,dtype=np.float64))\n",
        "          mb[k]/=(1-np.power(beta1,t,dtype=np.float64))\n",
        "          vw[k]=np.divide(vw[k],(1-np.power(beta2,t,dtype=np.float64)))\n",
        "          vb[k]=np.divide(vb[k],(1-np.power(beta2,t,dtype=np.float64)))\n",
        "          W[k]=np.subtract(W[k],((eta/batchsize)/np.sqrt(vw[k]+eps))*mw[k])\n",
        "          B[k]=np.subtract(B[k],((eta/batchsize)/np.sqrt(vb[k]+eps))*mb[k])\n",
        "          uw[k]=np.subtract(uw[k],uw[k])\n",
        "          ub[k]=np.subtract(ub[k],ub[k]) \n",
        "            \n",
        "    end = time.time() \n",
        "    tloss,tacc=train_acc_loss(W,B,activation,Ls_fun,wd)\n",
        "    vloss,vacc=val_acc_loss(W,B,activation,Ls_fun,wd)\n",
        "    wandb.log({\"epoch\":e,\"Train_loss\":tloss,\"Train_acc\":tacc,\"val_loss\":vloss,\"val_Accuracy\":vacc})\n",
        "    #print(\"epochs :\",e,\"train_loss :\",tloss,\"  Train_acc:\",tacc,\"val_loss:\",vloss,\"val_Accuracy:\",vacc,\"    time:\",math.ceil(end-start))\n",
        "  test_acc(W,B,activation,Ls_fun)  \n",
        "  return hi,W,B\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def NAdam(ftrx,ftry,init,batchsize,eps,beta1,beta2,wd,eta,N,nrl,activation,Ls_fun,epochs=1):\n",
        "  W,B=InitParams(nrl,init)\n",
        "  vw,vb,_,_=initgrads(N,nrl)\n",
        "  mw,mb,_,_=initgrads(N,nrl)\n",
        "  beta1=0.9\n",
        "  e=0\n",
        "  t=1\n",
        "  while(epochs>0):\n",
        "    e+=1\n",
        "    start = time.time()\n",
        "    epochs-=1\n",
        "    uw,ub,_,_=initgrads(N,nrl)\n",
        "    for i in range(len(ftrx[:54000])):\n",
        "      pred_y,ai,hi=Feed_Frwd_Nw1(ftrx[i],W,B,activation,Ls_fun)\n",
        "      gw,gb=Back_Prop(ftrx[i],pred_y,ftry[i],ai,hi,W,B,N,nrl,activation,Ls_fun)\n",
        "      for j in range(len(gw)):\n",
        "        uw[j]=np.add(uw[j],gw[j]+wd*W[j])\n",
        "        ub[j]=np.add(ub[j],gb[j]+wd*B[j])\n",
        "      if((i+1)%batchsize==0 or i==53999):\n",
        "        t+=1\n",
        "        for k in range(len(gw)):\n",
        "          vw[k]=np.add(beta2*vw[k],(1-beta2)*uw[k]**2)\n",
        "          vb[k]=np.add(beta2*vb[k],(1-beta2)*ub[k]**2)\n",
        "\n",
        "          mw[k]=np.add(beta1*mw[k],(1-beta1)*uw[k])\n",
        "          mb[k]=np.add(beta1*mb[k],(1-beta1)*ub[k])\n",
        "          mw[k]/=(1-np.power(beta1,t,dtype=np.float64))\n",
        "          mb[k]/=(1-np.power(beta1,t,dtype=np.float64))\n",
        "          vw[k]=np.divide(vw[k],(1-np.power(beta2,t,dtype=np.float64)))\n",
        "          vb[k]=np.divide(vb[k],(1-np.power(beta2,t,dtype=np.float64)))\n",
        "          W[k]=np.subtract(W[k],((eta/batchsize)/np.sqrt(vw[k]+eps))*((beta1*mw[k]+(1-beta1)*uw[k])/(1-beta1**t)))\n",
        "          B[k]=np.subtract(B[k],((eta/batchsize)/np.sqrt(vb[k]+eps))*((beta1*mb[k]+(1-beta1)*ub[k])/(1-beta1**t)))\n",
        "          uw[k]=np.subtract(uw[k],uw[k])\n",
        "          ub[k]=np.subtract(ub[k],ub[k]) \n",
        "            \n",
        "    end = time.time() \n",
        "    tloss,tacc=train_acc_loss(W,B,activation,Ls_fun,wd)\n",
        "    vloss,vacc=val_acc_loss(W,B,activation,Ls_fun,wd)\n",
        "    wandb.log({\"epoch\":e,\"Train_loss\":tloss,\"Train_acc\":tacc,\"val_loss\":vloss,\"val_Accuracy\":vacc})\n",
        "    #print(\"epochs :\",e,\"train_loss :\",tloss,\"  Train_acc:\",tacc,\"val_loss:\",vloss,\"val_Accuracy:\",vacc,\"    time:\",math.ceil(end-start))\n",
        "  test_acc(W,B,activation,Ls_fun)  \n",
        "  return hi,W,B\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "Y0sar2HROdQQ",
        "outputId": "562cd7a8-747e-4fd6-c727-2305874511f4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "                    Syncing run <strong><a href=\"https://wandb.ai/pratap49/mnist/runs/2sevs1ka\" target=\"_blank\">genial-rain-1</a></strong> to <a href=\"https://wandb.ai/pratap49/mnist\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
              "\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/pratap49/mnist/runs/2sevs1ka?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7fe88da5c090>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wandb.init(project=\"mnist\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3cyr-PXOdG9",
        "outputId": "62bb0a13-6cb9-44c9-d3f6-28f41ce82146"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb.plots.* functions are deprecated and will be removed in a future release. Please use wandb.plot.* instead.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Visualizing heatmap.\n"
          ]
        }
      ],
      "source": [
        "epochs = 15                                       \n",
        "batchsize = 32                                                    \n",
        "weightDecay = 0.00005                                           \n",
        "hidden_layer_size = 128\n",
        "weights_initializer='Xaviuor'                               \n",
        "lr=0.0095\n",
        "activation='tanh'                                            \n",
        "optimizer = \"adam\"                      \n",
        "num_hidden_layers= 3           \n",
        "lossfun = \"mse\"\n",
        "\n",
        "wandb.run.name=\"e_{}_hls_{}_numhl_{}_opt_{}_bs_{}_init_{}_ac_{}_loss_{}_learning_rate_{}_wdecay_{}\".format(epochs,\\\n",
        "                                                                      hidden_layer_size,\\\n",
        "                                                                      num_hidden_layers,\\\n",
        "                                                                      optimizer,\\\n",
        "                                                                      batchsize,\\\n",
        "                                                                      weights_initializer,\\\n",
        "                                                                     activation,\\\n",
        "                                                                      lossfun,\\\n",
        "                                                                      lr,\\\n",
        "                                                                      weightDecay)\n",
        "nrl=[hidden_layer_size for i in range(num_hidden_layers)]\n",
        "param=Adam(ftrx,ftry,weights_initializer,batchsize,1e-8,0.9,0.9,weightDecay,lr,num_hidden_layers,nrl,activation,lossfun,epochs)\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403,
          "referenced_widgets": [
            "941a90f1685249559cc16d7833220f0e",
            "21ee0502e3394a9ebeee36788c68d2d4",
            "1df22fe828ad410d97f1d62ded98747b",
            "5c3ed150fd644c36a44a969b0fe3b530",
            "bf13477f945041b99cd1efcc3a006d6e",
            "5f00929b06ab4733832876edf24c7dd4",
            "d86a156ff03d4722825943e5d29d4c89",
            "02c3d286c8554aa19625f5bcb6594654"
          ]
        },
        "id": "eAjNKCjRX5kp",
        "outputId": "99c2bea6-ab3b-47e6-b0ec-71f05b16fd53"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Finishing last run (ID:2sevs1ka) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 287... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "941a90f1685249559cc16d7833220f0e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.01MB of 0.01MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
              "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Accuracy</td><td>▁</td></tr><tr><td>Train_acc</td><td>▁▄▆▆▇▇▇▇███████</td></tr><tr><td>Train_loss</td><td>█▅▃▃▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>val_Accuracy</td><td>▁▄▆▆▇▇▇▇███████</td></tr><tr><td>val_loss</td><td>█▅▃▃▂▂▂▂▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
              "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Accuracy</td><td>0.9709</td></tr><tr><td>Train_acc</td><td>0.9857</td></tr><tr><td>Train_loss</td><td>0.01138</td></tr><tr><td>epoch</td><td>15</td></tr><tr><td>val_Accuracy</td><td>0.9855</td></tr><tr><td>val_loss</td><td>0.01086</td></tr></table>\n",
              "</div></div>\n",
              "Synced 5 W&B file(s), 2 media file(s), 2 artifact file(s) and 0 other file(s)\n",
              "<br/>Synced <strong style=\"color:#cdcd00\">genial-rain-1</strong>: <a href=\"https://wandb.ai/pratap49/mnist/runs/2sevs1ka\" target=\"_blank\">https://wandb.ai/pratap49/mnist/runs/2sevs1ka</a><br/>\n",
              "Find logs at: <code>./wandb/run-20220225_142633-2sevs1ka/logs</code><br/>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Successfully finished last run (ID:2sevs1ka). Initializing new run:<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "                    Syncing run <strong><a href=\"https://wandb.ai/pratap49/mnist/runs/3nll5ozv\" target=\"_blank\">cool-plasma-2</a></strong> to <a href=\"https://wandb.ai/pratap49/mnist\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
              "\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/pratap49/mnist/runs/3nll5ozv?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7fe88d9728d0>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wandb.init(project=\"mnist\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-fMDsHokX87M",
        "outputId": "96090901-fe56-4d24-c121-e6c59fead2ba"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Visualizing heatmap.\n"
          ]
        }
      ],
      "source": [
        "epochs = 15                                       \n",
        "batchsize = 32                                                    \n",
        "weightDecay = 0.00005                                           \n",
        "hidden_layer_size = 64\n",
        "weights_initializer='Xaviuor'                               \n",
        "lr=0.0055\n",
        "activation='tanh'                                            \n",
        "optimizer = \"nadam\"                      \n",
        "num_hidden_layers= 1           \n",
        "lossfun = \"ce\"\n",
        "\n",
        "wandb.run.name=\"e_{}_hls_{}_numhl_{}_opt_{}_bs_{}_init_{}_ac_{}_loss_{}_learning_rate_{}_wdecay_{}\".format(epochs,\\\n",
        "                                                                      hidden_layer_size,\\\n",
        "                                                                      num_hidden_layers,\\\n",
        "                                                                      optimizer,\\\n",
        "                                                                      batchsize,\\\n",
        "                                                                      weights_initializer,\\\n",
        "                                                                     activation,\\\n",
        "                                                                      lossfun,\\\n",
        "                                                                      lr,\\\n",
        "                                                                      weightDecay)\n",
        "nrl=[hidden_layer_size for i in range(num_hidden_layers)]\n",
        "param=NAdam(ftrx,ftry,weights_initializer,batchsize,1e-8,0.9,0.9,weightDecay,lr,num_hidden_layers,nrl,activation,lossfun,epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "sPQdkw_aYmrq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420,
          "referenced_widgets": [
            "5700acf3adeb43c9bb768448766421fc"
          ]
        },
        "outputId": "70dc0572-3645-4765-d1f7-178a7793c213"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Finishing last run (ID:3nll5ozv) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 462... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5700acf3adeb43c9bb768448766421fc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.01MB of 0.01MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
              "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Accuracy</td><td>▁</td></tr><tr><td>Train_acc</td><td>▁▄▅▆▆▆▇▇▇▇█████</td></tr><tr><td>Train_loss</td><td>█▅▄▃▃▃▂▂▂▂▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>val_Accuracy</td><td>▁▄▅▆▆▆▇▇▇▇█████</td></tr><tr><td>val_loss</td><td>█▅▄▃▃▂▂▂▂▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
              "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Accuracy</td><td>0.9624</td></tr><tr><td>Train_acc</td><td>0.96846</td></tr><tr><td>Train_loss</td><td>0.1115</td></tr><tr><td>epoch</td><td>15</td></tr><tr><td>val_Accuracy</td><td>0.97333</td></tr><tr><td>val_loss</td><td>0.10008</td></tr></table>\n",
              "</div></div>\n",
              "Synced 5 W&B file(s), 2 media file(s), 2 artifact file(s) and 0 other file(s)\n",
              "<br/>Synced <strong style=\"color:#cdcd00\">cool-plasma-2</strong>: <a href=\"https://wandb.ai/pratap49/mnist/runs/3nll5ozv\" target=\"_blank\">https://wandb.ai/pratap49/mnist/runs/3nll5ozv</a><br/>\n",
              "Find logs at: <code>./wandb/run-20220225_151921-3nll5ozv/logs</code><br/>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Successfully finished last run (ID:3nll5ozv). Initializing new run:<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    Syncing run <strong><a href=\"https://wandb.ai/pratap49/mnist/runs/jnoyvhfu\" target=\"_blank\">lunar-dragon-3</a></strong> to <a href=\"https://wandb.ai/pratap49/mnist\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
              "\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7fe8883217d0>"
            ],
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/pratap49/mnist/runs/jnoyvhfu?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "wandb.init(project=\"mnist\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Z4FpckRcYnvD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41e8bb5f-d08a-44f9-c9ca-a729e9fc586c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Visualizing heatmap.\n"
          ]
        }
      ],
      "source": [
        "epochs = 15                                       \n",
        "batchsize = 32                                                    \n",
        "weightDecay = 0.00005                                           \n",
        "hidden_layer_size = 32\n",
        "weights_initializer='Xaviuor'                               \n",
        "lr=0.04\n",
        "activation='relu'                                            \n",
        "optimizer = \"nadam\"                      \n",
        "num_hidden_layers= 2           \n",
        "lossfun = \"ce\"\n",
        "\n",
        "wandb.run.name=\"e_{}_hls_{}_numhl_{}_opt_{}_bs_{}_init_{}_ac_{}_loss_{}_learning_rate_{}_wdecay_{}\".format(epochs,\\\n",
        "                                                                      hidden_layer_size,\\\n",
        "                                                                      num_hidden_layers,\\\n",
        "                                                                      optimizer,\\\n",
        "                                                                      batchsize,\\\n",
        "                                                                      weights_initializer,\\\n",
        "                                                                     activation,\\\n",
        "                                                                      lossfun,\\\n",
        "                                                                      lr,\\\n",
        "                                                                      weightDecay)\n",
        "nrl=[hidden_layer_size for i in range(num_hidden_layers)]\n",
        "param=NAdam(ftrx,ftry,weights_initializer,batchsize,1e-8,0.9,0.9,weightDecay,lr,num_hidden_layers,nrl,activation,lossfun,epochs)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Question 10.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP2p9Y+8B8fyXSvqHoeceNC",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02c3d286c8554aa19625f5bcb6594654": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1df22fe828ad410d97f1d62ded98747b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d86a156ff03d4722825943e5d29d4c89",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_02c3d286c8554aa19625f5bcb6594654",
            "value": 1
          }
        },
        "21ee0502e3394a9ebeee36788c68d2d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf13477f945041b99cd1efcc3a006d6e",
            "placeholder": "​",
            "style": "IPY_MODEL_5f00929b06ab4733832876edf24c7dd4",
            "value": " 0.02MB of 0.02MB uploaded (0.00MB deduped)\r"
          }
        },
        "5c3ed150fd644c36a44a969b0fe3b530": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f00929b06ab4733832876edf24c7dd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "941a90f1685249559cc16d7833220f0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_21ee0502e3394a9ebeee36788c68d2d4",
              "IPY_MODEL_1df22fe828ad410d97f1d62ded98747b"
            ],
            "layout": "IPY_MODEL_5c3ed150fd644c36a44a969b0fe3b530"
          }
        },
        "bf13477f945041b99cd1efcc3a006d6e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d86a156ff03d4722825943e5d29d4c89": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}